# Data-Collection-Pipeline
This project demonstrates how webscraping is done using diffent libraries to create python classes using different methods to exctract/collect data from the chosen website from browsing, collecting, saving the data in the database. Below are many milestones to follow in order to complete the project successfully. 

**Task 1: Create Environment, Set Up Web Driver, Install Dependencies.**

conda create --name Data_Collection_Pipeline

pip3 install selenium

pip3 install pandas

Set up the Web Driver downloading ChromeDriver Manager,
For this Webscraping project had downloaded google-chrome version is 102.0.5005 to be used as a main driver for this project.

![image](https://user-images.githubusercontent.com/98617552/173931325-7d3fde90-b44c-4674-a157-e5fd127f2db4.png)

**Task 2: Create a Scraper class and methods **

![image](https://user-images.githubusercontent.com/98617552/174075463-f8f89ee8-73b8-45a5-b45b-76bcc2d26435.png)



**Task 3: Collect Data from URL and image Data.**

![image](https://user-images.githubusercontent.com/98617552/174076235-068a3cee-0212-41d6-a51b-9395ca088bff.png)


![image](https://user-images.githubusercontent.com/98617552/174076697-94b8e455-9cb9-4c62-9c74-6b78fba37d2e.png)



![image](https://user-images.githubusercontent.com/98617552/174077170-6ee5efaa-12b5-4b78-af28-6166e3be479b.png)


**Task 4: Unit Testing , Integration Testing and Documentation **
import unittest
import selenium

install unittest, its a built-in module to help you write and run tests for your python code.

![image](https://user-images.githubusercontent.com/98617552/174456955-66d72f0f-023d-44cc-b1ce-61549ea4277c.png)




